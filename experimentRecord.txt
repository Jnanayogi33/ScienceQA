------------------------------------------------------------------------------
11/2/2015 - First comparison between similarity and shortest-path (jump) tests

Inputs:
- Rough download of wikipedia articles with many holes (TY original) used to train word2vec and tfidf matrix
- QA pairs on training_set.tsv related to solar system used to evaluate system
Setup of similarity test:
- Take average word2vec arrays of question and answer
- Choose answer with highest dotproduct between question and answer
Setup of jump test
- lemmatization + porter stemming + strip punctuation
- basic parse into A <-> B form (two-sided) based on prepositions and S-V-O using Stanford Parser
- Add title and subtitle into low tf-idf phrases to make more descriptive
- Graph based on one wikipedia article ("Solar System") 550 sentences
- Uniform cost edges, either represent original parse or between nodes that are extremely similar
- Solve for shortest path between question and answer with djikstra's
- Return first answer with shortest path
Basic outputs
- Similarity test right: 9/33
- Jump test right: 10/33
- Number similarity got right that jump got wrong: 4
- Number jump got right that similarity got wrong: 4

